# -*- coding: utf-8 -*-
"""
scrapers/emmoto.py
Scraper para EM Moto (em-moto.com) - Nov 2025

Caracter√≠sticas:
- Site Magento com pesquisa direta por URL
- Estrutura de produtos bem definida
- Pre√ßos em data-price-amount
"""
import re
from typing import Optional, List, Dict
from urllib.parse import quote_plus

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

from core.validation import validate_product_match
from core.selenium_utils import get_page_html, try_accept_cookies
from config import STORE_URLS
from .base import BaseScraper, SearchResult, parse_price_to_float


CODE_SCAN = re.compile(r"[A-Z0-9][A-Z0-9\.\-_+]{2,}", re.I)


class EMMotoScraper(BaseScraper):
    """Scraper para EM Moto"""
    
    def __init__(self):
        super().__init__(
            name="emmoto",
            base_url=STORE_URLS.get("emmoto", "https://em-moto.com/")
        )
    
    def search_product(self, driver: webdriver.Chrome, 
                      ref_parts: List[str],
                      ref_raw: str = "") -> Optional[SearchResult]:
        """
        Busca produto na EM Moto
        
        Estrat√©gia:
        1. Vai direto para URL de pesquisa com a refer√™ncia
        2. Extrai lista de produtos dos resultados
        3. Valida cada produto contra a refer√™ncia
        4. Retorna o primeiro match v√°lido
        
        Args:
            driver: WebDriver Selenium
            ref_parts: Partes normalizadas (para valida√ß√£o)
            ref_raw: Refer√™ncia original (para pesquisar)
            
        Returns:
            SearchResult se encontrado, None caso contr√°rio
        """
        # Usar ref_raw se dispon√≠vel, sen√£o juntar ref_parts
        if ref_raw:
            ref_query = ref_raw
        else:
            ref_query = "+".join(ref_parts)
        
        print(f"  [EM Moto] Procurando: {ref_query}")
        
        # Construir URL de pesquisa
        search_url = f"{self.base_url}en/catalogsearch/result/?q={quote_plus(ref_query)}"
        
        try:
            # Ir direto para p√°gina de resultados
            driver.get(search_url)
            
            # Aceitar cookies se aparecerem
            try_accept_cookies(driver)
            
            import time
            time.sleep(1.5)  # Esperar p√°gina carregar
            
            # Verificar se h√° resultados
            try:
                WebDriverWait(driver, 5).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, ".products.list.items.product-items"))
                )
                print(f"  [EM Moto] ‚úì P√°gina de resultados carregada")
            except Exception:
                print(f"  [EM Moto] ‚ùå Sem resultados para esta pesquisa")
                return None
            
            # Extrair HTML
            soup = BeautifulSoup(driver.page_source, "lxml")
            
            # Procurar produtos
            products = soup.select("li.item.product.product-item")
            
            if not products:
                print(f"  [EM Moto] ‚ùå Nenhum produto encontrado")
                return None
            
            print(f"  [EM Moto] Encontrados {len(products)} produto(s)")
            
            # Processar cada produto
            for idx, product in enumerate(products[:5], 1):  # Limitar a 5 primeiros
                try:
                    # Extrair URL do produto
                    link = product.select_one("a.product-item-link")
                    if not link or not link.get("href"):
                        continue
                    
                    url = link["href"]
                    if not url.startswith("http"):
                        url = self.base_url.rstrip("/") + url
                    
                    # Extrair nome do produto (para debug)
                    product_name = link.get_text(strip=True)
                    print(f"  [EM Moto] [{idx}] {product_name[:60]}...")
                    print(f"  [EM Moto]       URL: {url[:80]}...")
                    
                    # Extrair pre√ßo da listagem (mais r√°pido)
                    price_text = self._extract_price_from_listing(product)
                    
                    if not price_text:
                        # Se n√£o encontrou na listagem, tentar na p√°gina do produto
                        print(f"  [EM Moto]       Carregando p√°gina do produto...")
                        prod_html = get_page_html(driver, url)
                        if prod_html:
                            price_text = self._extract_price_from_product_page(prod_html)
                    
                    if not price_text:
                        print(f"  [EM Moto]       ‚ùå Sem pre√ßo")
                        continue
                    
                    print(f"  [EM Moto]       üí∞ Pre√ßo: {price_text}")
                    
                    # Extrair identificadores da p√°gina do produto (para valida√ß√£o robusta)
                    prod_html = get_page_html(driver, url)
                    if not prod_html:
                        print(f"  [EM Moto]       ‚ö†Ô∏è  Falhou carregar p√°gina")
                        continue
                    
                    identifiers = self._extract_identifiers(prod_html)
                    prod_soup = BeautifulSoup(prod_html, "lxml")
                    
                    # Validar produto
                    validation = validate_product_match(
                        our_parts=ref_parts,
                        page_identifiers=identifiers,
                        page_url=url,
                        page_text=prod_soup.get_text(" ", strip=True)
                    )
                    
                    print(f"  [EM Moto]       {'‚úÖ' if validation.is_valid else '‚ùå'} Valida√ß√£o: {validation.confidence:.2f} - {validation.reason}")
                    
                    if validation.is_valid:
                        return SearchResult(
                            url=url,
                            price_text=price_text,
                            price_num=parse_price_to_float(price_text),
                            validation=validation
                        )
                
                except Exception as e:
                    print(f"  [EM Moto]       ‚ö†Ô∏è  Erro ao processar produto: {e}")
                    continue
            
            print(f"  [EM Moto] ‚ö†Ô∏è  Nenhum match v√°lido encontrado")
            return None
        
        except Exception as e:
            print(f"  [EM Moto] ‚ùå ERRO: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _extract_price_from_listing(self, product_element) -> Optional[str]:
        """
        Extrai pre√ßo da listagem de produtos (mais r√°pido)
        
        Args:
            product_element: Elemento BeautifulSoup do produto
            
        Returns:
            Pre√ßo formatado ou None
        """
        # M√âTODO 1: data-price-amount no span.price-wrapper
        price_wrapper = product_element.select_one("span.price-wrapper[data-price-amount]")
        if price_wrapper:
            price_amount = price_wrapper.get("data-price-amount")
            if price_amount:
                try:
                    price_float = float(price_amount)
                    return f"‚Ç¨{price_float:.2f}"
                except ValueError:
                    pass
        
        # M√âTODO 2: Texto do span.price dentro de special-price (pre√ßo promocional)
        special_price = product_element.select_one("span.special-price span.price")
        if special_price:
            price_text = special_price.get_text(strip=True)
            if price_text and "‚Ç¨" in price_text:
                return price_text
        
        # M√âTODO 3: Pre√ßo regular (se n√£o h√° promocional)
        regular_price = product_element.select_one("span.price-wrapper span.price")
        if regular_price:
            price_text = regular_price.get_text(strip=True)
            if price_text and "‚Ç¨" in price_text:
                return price_text
        
        return None
    
    def _extract_price_from_product_page(self, html: str) -> Optional[str]:
        """
        Extrai pre√ßo da p√°gina individual do produto
        
        Args:
            html: HTML da p√°gina do produto
            
        Returns:
            Pre√ßo formatado ou None
        """
        soup = BeautifulSoup(html, "lxml")
        
        # M√âTODO 1: Meta tag product:price:amount (Open Graph)
        meta_price = soup.select_one('meta[property="product:price:amount"]')
        if meta_price:
            price = meta_price.get("content")
            if price:
                try:
                    price_float = float(price)
                    return f"‚Ç¨{price_float:.2f}"
                except ValueError:
                    pass
        
        # M√âTODO 2: data-price-amount no price-wrapper
        price_wrapper = soup.select_one("span.price-wrapper[data-price-amount]")
        if price_wrapper:
            price_amount = price_wrapper.get("data-price-amount")
            if price_amount:
                try:
                    price_float = float(price_amount)
                    return f"‚Ç¨{price_float:.2f}"
                except ValueError:
                    pass
        
        # M√âTODO 3: Texto do pre√ßo especial (se houver promo√ß√£o)
        special_price = soup.select_one("span.special-price span.price")
        if special_price:
            price_text = special_price.get_text(strip=True)
            if price_text and "‚Ç¨" in price_text:
                return price_text
        
        # M√âTODO 4: Pre√ßo normal
        normal_price = soup.select_one(".price-box span.price")
        if normal_price:
            price_text = normal_price.get_text(strip=True)
            if price_text and "‚Ç¨" in price_text:
                return price_text
        
        # M√âTODO 5: JSON-LD (fallback)
        import json
        for script_tag in soup.find_all("script", type="application/ld+json"):
            try:
                data = json.loads(script_tag.string or "")
                
                def find_price(obj):
                    if isinstance(obj, dict):
                        if obj.get("@type") == "Product":
                            offers = obj.get("offers", {})
                            if isinstance(offers, dict):
                                price = offers.get("price")
                                if price:
                                    return f"‚Ç¨{float(price):.2f}"
                        
                        for v in obj.values():
                            result = find_price(v)
                            if result:
                                return result
                    
                    elif isinstance(obj, list):
                        for item in obj:
                            result = find_price(item)
                            if result:
                                return result
                    
                    return None
                
                price = find_price(data)
                if price:
                    return price
            
            except Exception:
                pass
        
        return None
    
    def _extract_identifiers(self, html: str) -> Dict[str, List[str]]:
        """
        Extrai identificadores da p√°gina para valida√ß√£o
        
        Args:
            html: HTML da p√°gina
            
        Returns:
            Dicion√°rio com listas de identificadores (sku, mpn, codes)
        """
        soup = BeautifulSoup(html, "lxml")
        ids = {"sku": [], "mpn": [], "codes": []}
        
        # Extrair do t√≠tulo
        if soup.title and soup.title.string:
            ids["codes"].extend(CODE_SCAN.findall(soup.title.string.upper()))
        
        # Extrair de meta keywords
        for meta in soup.find_all("meta", attrs={"name": re.compile("keywords", re.I)}):
            content = meta.get("content", "")
            ids["codes"].extend(CODE_SCAN.findall(content.upper()))
        
        # Extrair de Open Graph
        for meta in soup.find_all("meta", attrs={"property": re.compile("^og:(title|description)$", re.I)}):
            content = meta.get("content", "")
            ids["codes"].extend(CODE_SCAN.findall(content.upper()))
        
        # Procurar data-product-sku (espec√≠fico Magento)
        for element in soup.find_all(attrs={"data-product-sku": True}):
            sku = element.get("data-product-sku", "").strip().upper()
            if sku:
                ids["sku"].append(sku)
                ids["codes"].append(sku)
        
        # Extrair do texto da p√°gina (breadcrumbs, descri√ß√µes, etc)
        full_text = soup.get_text(" ", strip=True).upper()
        ids["codes"].extend(CODE_SCAN.findall(full_text))
        
        # Remover duplicados mantendo ordem
        for key in ids:
            ids[key] = list(dict.fromkeys(ids[key]))
        
        return ids
